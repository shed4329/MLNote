# Project:基于KNN的鸢尾花分类模型

## 项目简介
本项目基于经典的**鸢尾花（Iris）数据集**，实现K近邻（KNN）多分类算法，核心目标是通过遍历不同K值（近邻数量）和距离度量方式，筛选出最优模型，并完成鸢尾花品种（山鸢尾、变色鸢尾、维吉尼亚鸢尾）的分类任务。项目包含数据划分、参数调优、模型评估、可视化对比与模型保存功能，适合机器学习入门者理解KNN算法的基本流程与参数优化逻辑。




## 环境依赖
需安装Python 3.7及以上版本，并配置以下依赖库：
```bash
pip install numpy matplotlib scikit-learn
```
各库作用说明：
- `numpy`：提供数值计算支持（如数组操作、筛选最优模型）
- `matplotlib`：绘制参数对比可视化图表
- `scikit-learn`：加载数据集、实现KNN模型、计算评估指标
- `pickle`：Python内置库，用于模型序列化保存（无需额外安装）


## 数据集说明
使用`scikit-learn`内置的**Iris数据集**，具体信息如下：

| 项目                | 详情                                                                 |
|---------------------|----------------------------------------------------------------------|
| 样本总数            | 150条                                                                 |
| 特征数量            | 4个（均为数值型，单位：厘米）：<br>1. 萼片长度（sepal length）<br>2. 萼片宽度（sepal width）<br>3. 花瓣长度（petal length）<br>4. 花瓣宽度（petal width） |
| 类别数量            | 3个（多分类任务）：<br>- 0: setosa（山鸢尾）<br>- 1: versicolor（变色鸢尾）<br>- 2: virginica（维吉尼亚鸢尾） |
| 数据划分比例        | 训练集（50%，75条）→ 验证集（20%，30条）→ 测试集（30%，45条）       |


## 代码结构与功能
### 1. 核心函数说明
| 函数名                  | 输入参数                                                                 | 输出/功能描述                                                                 |
|-------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| `load_and_split()`      | 无                                                                       | 返回划分后的训练集/验证集/测试集（X_train/X_dev/X_test）、对应标签（y_train/y_dev/y_test）、类别名称（class_names）；打印各数据集大小 |
| `evaluate_knn_parameters()` | X_train, y_train, X_dev, y_dev, k_values, metrics                         | 遍历所有K值和距离度量组合，训练KNN模型并在验证集评估；返回所有参数结果列表和最优模型；打印各组合的验证集准确率 |
| `evaluate_best_model()` | best_model, X_test, y_test                                               | 用最优模型在测试集评估，输出测试集准确率和分类报告；将分类报告保存为`result.txt`；返回测试集准确率 |
| `plot_results()`        | results（参数评估结果列表）                                              | 生成“K值+距离度量”与验证集准确率的关系图，保存为`hyperparameter.png`；弹出图表窗口 |
| 主程序（`if __name__ == '__main__'`） | 无                                                                       | 定义参数范围、执行完整流程（数据划分→参数评估→最优模型测试→可视化→模型保存）；保存最优模型为`iris_knn_model.pkl` |

### 2. 关键参数配置
在主程序中可调整的核心参数：
```python
# 待测试的K值（近邻数量，建议选奇数避免投票平局）
k_values = [1, 3, 5, 7, 9, 11]
# 待测试的距离度量方式
distance_metrics = ['euclidean', 'manhattan', 'chebyshev']
```
各距离度量说明：
- `euclidean`（欧式距离）：两点间直线距离，适用于特征尺度一致的场景（Iris数据集默认最优）。
- `manhattan`（曼哈顿距离）：坐标轴方向移动的“城市街区距离”，对异常值更鲁棒。
- `chebyshev`（切比雪夫距离）：各特征维度差值的最大值，适用于关注“极端差异”的场景。


## 快速使用指南
### 1. 运行代码
1打开终端，切换到代码所在目录，执行命令：
   ```bash
   python model.py
   ```

### 2. 运行输出
执行后将依次打印以下信息（示例）：
```
# 1. 数据划分结果
训练集大小: 75
验证集大小: 30
测试集大小: 45

# 2. 各参数组合的验证集准确率
距离度量: euclidean, K=1, 验证集准确率: 0.9667
距离度量: euclidean, K=3, 验证集准确率: 1.0000
距离度量: euclidean, K=5, 验证集准确率: 0.9667
...（省略其他距离度量的K值组合）

# 3. 最优参数与测试集评估
最佳参数: 距离度量=euclidean, K=3, 验证集准确率=1.0000
测试集准确率: 0.9778
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        14
  versicolor       0.94      1.00      0.97        16
   virginica       1.00      0.93      0.96        15

    accuracy                           0.98        45
   macro avg       0.98      0.98      0.98        45
weighted avg       0.98      0.98      0.98        45

评估报告已经保存为result.txt

# 4. 可视化与模型保存
超参数对比图已经保存为hyperparameter.png
模型已保存!
```

### 3. 生成文件说明
运行后将自动生成3个文件，保存在代码同级目录：

| 文件名                | 用途                                                                 |
|-----------------------|----------------------------------------------------------------------|
| `hyperparameter.png`  | 可视化图表：展示不同K值和距离度量对应的验证集准确率，可直观对比参数性能 |
| `result.txt`          | 文本文件：保存最优模型在测试集上的分类报告（精确率、召回率、F1分数）   |
| `iris_knn_model.pkl`  | 序列化模型文件：保存最优KNN模型，可直接加载用于新数据预测             |


## 模型加载与预测示例
若需使用已保存的`iris_knn_model.pkl`模型预测新数据，可参考以下代码：
```python
import pickle
import numpy as np

# 1. 加载保存的模型
with open('iris_knn_model.pkl', 'rb') as f:
    best_knn_model = pickle.load(f)

# 2. 准备新数据（需与训练数据特征顺序一致：萼片长度、萼片宽度、花瓣长度、花瓣宽度）
# 示例：2条新数据（分别为山鸢尾和维吉尼亚鸢尾的特征）
new_data = np.array([
    [5.1, 3.5, 1.4, 0.2],  # 山鸢尾（setosa）特征
    [6.5, 3.0, 5.2, 2.0]   # 维吉尼亚鸢尾（virginica）特征
])

# 3. 模型预测
predictions = best_knn_model.predict(new_data)
# 4. 映射预测结果到类别名称
class_names = ['setosa', 'versicolor', 'virginica']
for i, pred in enumerate(predictions):
    print(f"新数据{i+1} 预测类别：{class_names[pred]}（类别索引：{pred}）")
```


## 常见问题与解决方案
### 1. Q：运行代码时提示“模块找不到”？
A：检查是否已安装所有依赖库，执行`pip install numpy matplotlib scikit-learn`重新安装。

### 2. Q：加载模型时出现`pickle.UnpicklingError`？
A：模型保存与加载时的`scikit-learn`版本需一致（版本差异会导致序列化不兼容），建议使用相同版本或重新训练保存模型。

### 3. Q：为什么不同距离度量在Iris数据集上性能差异小？
A：Iris数据集的4个特征尺度相近（均为厘米级）且类别边界清晰，因此距离度量对结果影响较小；若使用特征尺度差异大的数据集（如房价、乳腺癌数据），需先通过`StandardScaler`标准化特征，距离度量的影响会更明显。

